{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeType(final):\n",
    "    tps = []\n",
    "    for i in range(len(final)-1):\n",
    "        if final[i+1][1] != '' and final[i][1] == '':\n",
    "            tps.append(i-len(tps))\n",
    "    return tps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeType([(['the', 'demise', 'of', '<Entity>'], ''), (['What', 'disease', 'led', 'to'], 'Disease')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = [(['the', 'demise', 'of', '<Entity>'], ''), (['What', 'disease', 'led', 'to'], 'Disease')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeType(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "from nltk.tree import ParentedTree\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from hierarchy import Hierarchy\n",
    "import ast\n",
    "import string\n",
    "\n",
    "nlp = StanfordCoreNLP('http://localhost', port=9000)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "specificStopWords = {'Give', 'Show', 'List', 'Name', 'Tell', 'many', 'much', 'all', 'whose', 'often', 'also', 'Count', 'Find', 'amongst', 'Amongst', 'among', 'Among', 'would'}\n",
    "whwords = {'How', 'Which', 'Who', 'Whose', 'Whom', 'When', 'Where', 'What', 'Give', 'Show', 'List', 'Name', 'Tell', 'Count', 'Find', 'what'}\n",
    "newstopwords = [line.strip() for line in open('stopwords').readlines()]\n",
    "yesnowords = {'is', 'are', 'were', 'was', 'do', 'does', 'did', 'has', 'have', 'had'}\n",
    "types = [(t.strip().upper(),t.strip()) for t in open('hierarchy.txt').readlines()]\n",
    "misstypes = [tuple(t.strip().split(',')) for t in open('./misstypes').readlines()]\n",
    "typedict = dict(types+misstypes)\n",
    "misstypedict = dict(misstypes)\n",
    "del typedict['TYPE']\n",
    "table = dict.fromkeys(string.punctuation)\n",
    "del table['<']\n",
    "del table['>']\n",
    "table = str.maketrans(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findQType(line):\n",
    "    line = line[0].upper() + line[1:]\n",
    "    lineSplitOrig = line.split()\n",
    "    if lineSplitOrig[1] == 'which':\n",
    "        lineSplitOrig[1] = 'Which'\n",
    "    elif lineSplitOrig[1] == 'what':\n",
    "        lineSplitOrig[1] = 'What'\n",
    "    line = ' '.join(lineSplitOrig)\n",
    "    ptree = ParentedTree.fromstring(nlp.parse(line))\n",
    "    firstw = lineSplitOrig[0].lower()\n",
    "    if firstw == 'who' or firstw == 'whom' or firstw == 'whose':\n",
    "        qt = 'Person'\n",
    "    elif firstw == 'when':\n",
    "        qt = 'Time'\n",
    "    elif firstw == 'where':\n",
    "        qt = 'Place'\n",
    "    else:\n",
    "        qt = ''\n",
    "    lineSplit = [x for x in lineSplitOrig if x.lower() not in newstopwords]\n",
    "    linetypes = {}\n",
    "    j = 0\n",
    "    while j < len(lineSplit):\n",
    "        for k in range(len(lineSplit), j, -1):\n",
    "            catl = lineSplit[j:k]\n",
    "            cat = ''.join(map(lambda x:lemmatizer.lemmatize(x.lower(), 'n').upper(), catl))\n",
    "            # for l in range(j, k+1):\n",
    "            #     wl = lineSplit[l]\n",
    "            #     cat += lemmatizer.lemmatize(wl.lower(), 'n').upper()\n",
    "            #     catl.append(wl)\n",
    "            if cat in typedict:\n",
    "                word = ' '.join(catl)\n",
    "                currtype = typedict[cat]\n",
    "                if word in linetypes or\\\n",
    "                    len(catl) == 1 and (word == 'place' and lineSplitOrig[lineSplitOrig.index(word)-1] in ['take', 'takes', 'took']\\\n",
    "                        or findPOS(ptree, word) != 'N'\\\n",
    "                        or lineSplit.index(word) != len(lineSplit) - 1 and findPOS(ptree, lineSplitOrig[lineSplitOrig.index(word)+1]) == 'N'):\n",
    "                    continue\n",
    "                if len(catl) > 1:\n",
    "                    linetypes[currtype] = currtype\n",
    "                    line = line.replace(word, currtype)\n",
    "                else:\n",
    "                    linetypes[word] = currtype\n",
    "                j = k\n",
    "                break\n",
    "        j += 1\n",
    "    return line, qt, linetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPOS(ptree, w):\n",
    "    w = w.translate(table)\n",
    "    if w in ptree.leaves():\n",
    "        return ptree[ptree.leaf_treeposition(ptree.leaves().index(w))[:-1]].label()[0]\n",
    "    else:\n",
    "        return 'P'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = 'From which party is the politician who was selected  in <E>?'\n",
    "print(findQType(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize('politician', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'POLITICIAN' in typedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(10,2,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('~/word2vec/GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lem(word):\n",
    "    if word in model.vocab:\n",
    "        return word\n",
    "    else:\n",
    "        vlem = lemmatizer.lemmatize(word, 'v')\n",
    "        if vlem != word and vlem in model.vocab:\n",
    "            return vlem\n",
    "        nlem = lemmatizer.lemmatize(word, 'n')\n",
    "        if nlem != word and nlem in model.vocab:\n",
    "            return nlem\n",
    "        alem = lemmatizer.lemmatize(word, 'a')\n",
    "        if alem != word and alem in model.vocab:\n",
    "            return alem\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineSplit = ['working']\n",
    "lvs = np.transpose(normalize(np.stack([model[lem(ls)] for ls in lineSplit if lem(ls) != ''])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model['birth'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predL = [['employer'],['founded']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([np.average(np.max(np.dot(normalize(np.stack([model[lem(ps)] for ps in predSplit if lem(ps) != ''])), lvs), axis=1)) for predSplit in predL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = PyDictionary.PyDictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d.meaning('employer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.meaning('work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'own' in model.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "from nltk.tree import ParentedTree\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import numpy as np\n",
    "from SPARQLWrapper import SPARQLWrapper,JSON\n",
    "from sklearn.preprocessing import normalize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# from GstoreConnector import GstoreConnector\n",
    "from hierarchy import Hierarchy\n",
    "import string\n",
    "import ast\n",
    "import json\n",
    "\n",
    "nlp = StanfordCoreNLP('http://localhost', port=9000)\n",
    "sparql = SPARQLWrapper(\"https://dbpedia.org/sparql\")\n",
    "# sparql = GstoreConnector(\"dbpedia.gstore-pku.com\", 80, \"endpoint\", \"123\")\n",
    "specificStopWords = {'Give', 'Show', 'List', 'Name', 'Tell', 'many', 'much', 'all', 'whose', 'often', 'also', 'Count', 'Find', 'amongst', 'among', 'would'}\n",
    "whwords = {'How', 'Which', 'Who', 'When', 'Where', 'What'}\n",
    "timetypes = {'Time','Year'}\n",
    "literaltypes = {'Population', 'Name'}\n",
    "timexmltypes = {'duration', 'dateTime', 'time', 'date', 'gYearMonth', 'gYear', 'gMonthDay', 'gDay', 'gMonth'}\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('~/word2vec/GoogleNews-vectors-negative300.bin',binary=True)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "table = dict.fromkeys(string.punctuation)\n",
    "del table['<']\n",
    "del table['>']\n",
    "table = str.maketrans(table)\n",
    "newstopwords = {line.strip() for line in open('stopwords').readlines()}\n",
    "otherwords = {'<Entity>', '<E1>', '<E2>', 'someone', 'everyone'}\n",
    "newstopwords = newstopwords | otherwords | specificStopWords\n",
    "\n",
    "def splitPre(pre):\n",
    "    ind = 0\n",
    "    preList = set()\n",
    "    for i in range(len(pre)):\n",
    "        if pre[i].isupper():\n",
    "            if i - ind>1:\n",
    "                word = lem(pre[ind:i].lower())\n",
    "                if word != '':\n",
    "                    preList.add(word)\n",
    "                ind = i\n",
    "    if len(preList)==0:\n",
    "        word = lem(pre.lower())\n",
    "        if word != '':\n",
    "            preList.add(word)\n",
    "    else:\n",
    "        word = lem(pre[ind:].lower())\n",
    "        if word != '':\n",
    "            preList.add(word)\n",
    "    return preList\n",
    "\n",
    "def generatePaths(path):\n",
    "    lineSplit = set()\n",
    "    for x in path:\n",
    "        x = x.translate(table)\n",
    "        if x!='' and x not in lineSplit and x not in newstopwords and x.lower() not in newstopwords:\n",
    "            word = lem(x.lower())\n",
    "            if word != '':\n",
    "                lineSplit.add(word)\n",
    "    return lineSplit\n",
    "\n",
    "\n",
    "def generateSPARQL(pline, resource):\n",
    "    qstart = 'SELECT DISTINCT '\n",
    "    qmiddle1 = 'WHERE {'\n",
    "    qmiddle2 = '} UNION {'\n",
    "    qend2 = '}. FILTER (isLiteral('\n",
    "    prevE = resource\n",
    "    query = qmiddle1\n",
    "    qstart1 = qstart\n",
    "    pathL = []\n",
    "    typeL = []\n",
    "    for pi in range(len(pline)):\n",
    "        pv = '?p' + str(pi)\n",
    "        ev = '?x' + str(pi)\n",
    "        path, answerT = pline[pi]\n",
    "        path = generatePaths(path)\n",
    "        if len(path) == 0 and len(pathL) != 0:\n",
    "            pathL.append(pathL[-1])\n",
    "        else:\n",
    "            pathL.append(path)\n",
    "        typeL.append(answerT)\n",
    "        qstart1 += pv + ' '\n",
    "        query += '{' + prevE + ' ' + pv + ' ' + ev + qmiddle2 + ev + ' ' + pv + ' ' + prevE\n",
    "        if answerT in literaltypes or answerT in timetypes:\n",
    "            query += qend2 + ev + ')).'\n",
    "        elif answerT == '':\n",
    "            query += '}.'\n",
    "        else:\n",
    "            query += '}.' + ev + ' a <http://dbpedia.org/ontology/' + answerT + '>.'\n",
    "        prevE = ev\n",
    "    query = qstart1 + query + '}'\n",
    "    print(query)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    return results, pathL, typeL\n",
    "\n",
    "def generatePreds(results):\n",
    "    predL = [[] for i in range(len(pline))]\n",
    "    predSplitL = [[] for i in range(len(pline))]\n",
    "    idL = [[] for i in range(1, len(pline))]\n",
    "    # print(len(results['results']['bindings']))\n",
    "    for t in results['results']['bindings']:\n",
    "        flag = False\n",
    "        currPreds = []\n",
    "        currPredSplits = []\n",
    "        for i in range(len(pline)):\n",
    "            currPred = t['p'+str(i)]['value']\n",
    "            if 'dbpedia.org' not in currPred or 'wikiPage' in currPred:\n",
    "                flag = True\n",
    "                break\n",
    "            currPredSplit = splitPre(currPred.split('/')[-1].split('#')[-1])\n",
    "            if len(currPredSplit) == 0:\n",
    "                flag = True\n",
    "                break\n",
    "            currPreds.append(currPred)\n",
    "            currPredSplits.append(currPredSplit)\n",
    "        if flag:\n",
    "            continue\n",
    "        prevId = -1\n",
    "        flag = False\n",
    "        for i in range(len(pline)):\n",
    "            if currPreds[i] not in predL[i]:\n",
    "                if prevId != -1:\n",
    "                    idL[i-1].append((prevId, len(predL[i])))\n",
    "                prevId = len(predL[i])\n",
    "                predL[i].append(currPreds[i])\n",
    "                predSplitL[i].append(currPredSplits[i])\n",
    "                # pvsL[i].append(splitVec(splitPre(currPreds[i].split('/')[-1].split('#')[-1])))\n",
    "            else:\n",
    "                currId = (prevId, predL[i].index(currPreds[i]))\n",
    "                if prevId != -1 and currId not in idL[i-1]:\n",
    "                    idL[i-1].append(currId)\n",
    "                prevId = currId[1]\n",
    "    return predL, predSplitL, idL\n",
    "\n",
    "def removeType(pline, h):\n",
    "    maxD = -1\n",
    "    for pi in range(len(pline)):\n",
    "        pt = pline[pi][1]\n",
    "        if pt != '':\n",
    "            depth = h.getDepth(pt)\n",
    "            if depth > maxD:\n",
    "                maxD = depth\n",
    "                maxId = pi\n",
    "    pline[maxId] = (pline[maxId][0],'')\n",
    "    return pline\n",
    "\n",
    "def computeSimVecNew(lineSplit, predSplit):\n",
    "    print(lineSplit)\n",
    "    print(predSplit)\n",
    "    lvs = np.transpose(normalize(np.stack([model[ls] for ls in lineSplit])))\n",
    "    return np.array([np.average(np.max(np.dot(normalize(np.stack([model[ps] for ps in pred])), lvs), axis=1)) for pred in predSplit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([2,3,6,5,4])\n",
    "b = np.array([[1,2,3],[0,4,2]])\n",
    "b[1] = a[b[1]]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper,JSON\n",
    "sparql = SPARQLWrapper(\"https://dbpedia.org/sparql\")\n",
    "sline = 'SELECT DISTINCT ?p0 ?p1 ?p2 FROM <http://dbpedia.org> WHERE {{<http://dbpedia.org/resource/NTSC> ?p0 ?x0} UNION {?x0 ?p0 <http://dbpedia.org/resource/NTSC>}.?x0 a <http://dbpedia.org/ontology/TelevisionShow>.{?x0 ?p1 ?x1} UNION {?x1 ?p1 ?x0}.{?x1 ?p2 <http://dbpedia.org/resource/Ron_Grainer>} UNION {<http://dbpedia.org/resource/Ron_Grainer> ?p2 ?x1}.}'\n",
    "sparql.setQuery(sline)\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "for t in results['results']['bindings']:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip([1],[2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left, bisect_right\n",
    "bisect_right([1,2,4,6,9],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0, 1, 0],\n",
    "       [1, 0, 1],\n",
    "       [0, 0, 0],\n",
    "       [1, 1, 0],\n",
    "       [0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[range(1,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.where(a.any(axis=0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(a[:,1]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[0, 1, 0, 1, 0],\n",
    "       [0, 1, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(np.dot(a, np.transpose(b))!=0, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,d=1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(np.zeros(a.shape, dtype=int)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(a[0]!=0)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import PriorityQueue as PQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq = PQ()\n",
    "pq.put((1, 'a'))\n",
    "pq.put((2, 'b'))\n",
    "pq.queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.put((3,'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'a' in pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = []\n",
    "heapq.heappush(q, (3,'A',5))\n",
    "heapq.heappush(q, (1,'B',4))\n",
    "heapq.heappush(q, (4,'C',2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(d, i):\n",
    "    d[i] = str(i)\n",
    "d = {}\n",
    "add(d,1)\n",
    "add(d,2)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(-1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import matplotlib.pyplot as plt\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank. [SEP]\n"
     ]
    }
   ],
   "source": [
    "text = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "print (marked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'after', 'stealing', 'money', 'from', 'the', 'bank', 'vault', ',', 'the', 'bank', 'robber', 'was', 'seen', 'fishing', 'on', 'the', 'mississippi', 'river', 'bank', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "print (tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knight',\n",
       " 'lap',\n",
       " 'survey',\n",
       " 'ma',\n",
       " '##ow',\n",
       " 'noise',\n",
       " 'billy',\n",
       " '##ium',\n",
       " 'shooting',\n",
       " 'guide',\n",
       " 'bedroom',\n",
       " 'priest',\n",
       " 'resistance',\n",
       " 'motor',\n",
       " 'homes',\n",
       " 'sounded',\n",
       " 'giant',\n",
       " '##mer',\n",
       " '150',\n",
       " 'scenes']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.vocab.keys())[5000:5020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[CLS]', 101)\n",
      "('after', 2044)\n",
      "('stealing', 11065)\n",
      "('money', 2769)\n",
      "('from', 2013)\n",
      "('the', 1996)\n",
      "('bank', 2924)\n",
      "('vault', 11632)\n",
      "(',', 1010)\n",
      "('the', 1996)\n",
      "('bank', 2924)\n",
      "('robber', 27307)\n",
      "('was', 2001)\n",
      "('seen', 2464)\n",
      "('fishing', 5645)\n",
      "('on', 2006)\n",
      "('the', 1996)\n",
      "('mississippi', 5900)\n",
      "('river', 2314)\n",
      "('bank', 2924)\n",
      "('.', 1012)\n",
      "('[SEP]', 102)\n"
     ]
    }
   ],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "  print (tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "segments_ids = [1] * len(tokenized_text)\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407873900/407873900 [14:20<00:00, 473737.87B/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 12\n",
      "Number of batches: 1\n",
      "Number of tokens: 22\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(encoded_layers))\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the 5th token in our sentence, select its feature values from layer 5.\n",
    "token_i = 5\n",
    "layer_i = 5\n",
    "vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in sequence: 22\n",
      "Number of layers per token: 12\n"
     ]
    }
   ],
   "source": [
    "# Convert the hidden state embeddings into single token vectors\n",
    "\n",
    "# Holds the list of 12 layer embeddings for each token\n",
    "# Will have the shape: [# tokens, # layers, # features]\n",
    "token_embeddings = [] \n",
    "\n",
    "# For each token in the sentence...\n",
    "for token_i in range(len(tokenized_text)):\n",
    "  \n",
    "  # Holds 12 layers of hidden states for each token \n",
    "  hidden_layers = [] \n",
    "  \n",
    "  # For each of the 12 layers...\n",
    "  for layer_i in range(len(encoded_layers)):\n",
    "    \n",
    "    # Lookup the vector for `token_i` in `layer_i`\n",
    "    vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "    \n",
    "    hidden_layers.append(vec)\n",
    "    \n",
    "  token_embeddings.append(hidden_layers)\n",
    "\n",
    "# Sanity check the dimensions:\n",
    "print (\"Number of tokens in sequence:\", len(token_embeddings))\n",
    "print (\"Number of layers per token:\", len(token_embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_last_4_layers = [torch.cat((layer[-1], layer[-2], layer[-3], layer[-4]), 0) for layer in token_embeddings] # [number_of_tokens, 3072]\n",
    "\n",
    "summed_last_4_layers = [torch.sum(torch.stack(layer)[-4:], 0) for layer in token_embeddings] # [number_of_tokens, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final sentence embedding vector of shape:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 768)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embedding = torch.mean(encoded_layers[11], 1)\n",
    "print (\"Our final sentence embedding vector of shape:\"), sentence_embedding[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\n"
     ]
    }
   ],
   "source": [
    "print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First fifteen values of 'bank' as in 'bank robber':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1868, -1.5298, -1.3770,  1.0648,  3.1446,  1.4003, -4.2407,  1.3946,\n",
       "        -0.1170, -1.8777,  0.1091, -0.3862,  0.6744,  2.1924, -4.5306])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"First fifteen values of 'bank' as in 'bank robber':\")\n",
    "summed_last_4_layers[10][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First fifteen values of 'bank' as in 'bank vault':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 2.1319, -2.1413, -1.6260,  0.8638,  3.3173,  0.1797, -4.4853,  3.1215,\n",
       "        -0.9740, -3.1780,  0.1045, -1.5481,  0.4758,  1.1703, -4.4859])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"First fifteen values of 'bank' as in 'bank vault':\")\n",
    "summed_last_4_layers[6][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First fifteen values of 'bank' as in 'river bank':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1295, -1.4725, -0.7296, -0.0901,  2.4970,  0.5330,  0.9742,  5.1834,\n",
       "        -1.0692, -1.5941,  1.9261,  0.7119, -0.9809,  1.2127, -2.9812])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"First fifteen values of 'bank' as in 'river bank':\")\n",
    "summed_last_4_layers[19][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compare \"bank\" as in \"bank robber\" to \"bank\" as in \"river bank\"\n",
    "different_bank = cosine_similarity(summed_last_4_layers[10].reshape(1,-1), summed_last_4_layers[19].reshape(1,-1))[0][0]\n",
    "\n",
    "# Compare \"bank\" as in \"bank robber\" to \"bank\" as in \"bank vault\" \n",
    "same_bank = cosine_similarity(summed_last_4_layers[10].reshape(1,-1), summed_last_4_layers[6].reshape(1,-1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of 'bank' as in 'bank robber' to 'bank' as in 'bank vault': 0.9456753\n"
     ]
    }
   ],
   "source": [
    "print (\"Similarity of 'bank' as in 'bank robber' to 'bank' as in 'bank vault':\",  same_bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of 'bank' as in 'bank robber' to 'bank' as in 'river bank': 0.6797334\n"
     ]
    }
   ],
   "source": [
    "print (\"Similarity of 'bank' as in 'bank robber' to 'bank' as in 'river bank':\",  different_bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "bc = BertClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[-0.19964133, -0.14115876, -0.34231967, ..., -0.9036322 ,\n",
       "           0.15148601,  0.1675286 ],\n",
       "         [ 0.39201322, -0.1717876 ,  0.86706764, ..., -2.0062697 ,\n",
       "           1.2954623 , -0.5227411 ],\n",
       "         [-0.6033677 , -0.16857448, -0.2074915 , ..., -1.135671  ,\n",
       "           1.634594  , -0.48202583],\n",
       "         ...,\n",
       "         [-0.        , -0.        ,  0.        , ..., -0.        ,\n",
       "           0.        , -0.        ],\n",
       "         [-0.        , -0.        ,  0.        , ..., -0.        ,\n",
       "           0.        , -0.        ],\n",
       "         [-0.        , -0.        , -0.        , ..., -0.        ,\n",
       "           0.        , -0.        ]]], dtype=float32),\n",
       " [['[CLS]',\n",
       "   'name',\n",
       "   'the',\n",
       "   'television',\n",
       "   'show',\n",
       "   'which',\n",
       "   'has',\n",
       "   'artist',\n",
       "   'named',\n",
       "   'entity',\n",
       "   '?',\n",
       "   '[SEP]']])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = 'Name the television show which has artist named Entity ?'\n",
    "vec = bc.encode([q], show_tokens=True)\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[-0.2415832 , -0.14309117, -0.20727731, ..., -0.595832  ,\n",
       "          -0.00849143, -0.02547919],\n",
       "         [-0.3987112 , -0.0562871 , -0.10846417, ..., -0.40035337,\n",
       "           0.66998273, -1.0524428 ],\n",
       "         [ 0.43796057,  0.625638  ,  0.55722535, ..., -0.5351783 ,\n",
       "          -0.1575391 ,  0.02589705],\n",
       "         ...,\n",
       "         [ 0.        , -0.        , -0.        , ...,  0.        ,\n",
       "          -0.        , -0.        ],\n",
       "         [ 0.        , -0.        , -0.        , ...,  0.        ,\n",
       "          -0.        , -0.        ],\n",
       "         [ 0.        , -0.        , -0.        , ...,  0.        ,\n",
       "          -0.        , -0.        ]]], dtype=float32),\n",
       " [['[CLS]', 'what', '[UNK]', 'leader', 'is', 'entity', '?', '[SEP]']])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qsplit = q.lower().split()\n",
    "vec = bc.encode([qsplit], is_tokenized=True, show_tokens=True)\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
